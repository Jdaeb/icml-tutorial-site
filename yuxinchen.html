<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Yuxin Chen ‚Äì ICML 2025</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
  <style>
    :root {
      --mint: #20cfc7;
      --dark: #1f1f1f;
    }
    body {
      font-family: 'Roboto', sans-serif;
      margin: 0;
      display: flex;
      color: #333;
      line-height: 1.9;
    }
    .sidebar {
      background: var(--dark);
      color: white;
      width: 250px;
      height: 100vh;
      padding: 30px 20px;
      position: fixed;
      transition: width 0.3s;
    }
    .sidebar.collapsed {
      width: 60px;
    }
    .sidebar img.logo {
      width: 60px;
      margin-bottom: 20px;
      cursor: pointer;
    }
    .sidebar.collapsed img.logo {
      display: block;
      margin: 0 auto 20px;
    }
    .sidebar nav a {
      display: flex;
      align-items: center;
      color: white;
      text-decoration: none;
      margin: 12px 0;
      padding: 10px;
      border-radius: 30px;
      transition: background 0.3s;
      white-space: nowrap;
    }
    .sidebar.collapsed nav a span {
      display: none;
    }
    .sidebar nav a:hover {
      background: var(--mint);
    }
    .sidebar hr {
      border: 0;
      height: 1px;
      background: #444;
      margin: 20px 0;
    }
    .main {
      margin-left: 250px;
      padding: 60px;
      width: calc(100% - 250px);
      max-width: none;
    }
    .sidebar.collapsed + .main {
      margin-left: 60px;
    }
    h1 {
      font-size: 24px;
      margin-bottom: 20px;
    }
    img.profile {
      width: 300px;
      float: right;
      margin-left: 20px;
      border-radius: 8px;
    }
    .figure {
      display: flex;
      gap: 20px;
      justify-content: center;
      margin-top: 40px;
    }
    .figure img {
      max-width: 45%;
      height: auto;
      border-radius: 4px;
    }
    .papers {
      margin-top: 40px;
    }
    .papers h3 {
      margin-top: 30px;
      font-size: 18px;
    }
    .papers li {
      margin-bottom: 10px;
    }
    .collapsed img.logo-toggle {
      display: block;
    }
  </style>
</head>
<body>
<div class="sidebar" id="sidebar">
  <img src="https://icml.cc/static/core/img/icml-navbar-logo.svg" class="logo" onclick="toggleSidebar()" alt="ICML Logo">
  <nav>
    <a href="index.html">üè† <span>Home</span></a>
    <a href="#schedule">üóì <span>Schedule</span></a>
    <a href="#speakers">üßë‚Äçüè´ <span>Speakers</span></a>
    <hr>
    <a href="qingqu.html">üë®‚Äçüî¨ <span>Qing Qu</span></a>
    <a href="#">üë®‚Äçüè´ <span>Yuxin Chen</span></a>
    <a href="#">üë©‚Äçüè´ <span>Liyue Shen</span></a>
  </nav>
</div>

<main class="main">
  <section class="section">
  <h2>Yuxin Chen (Sampling Theory)</h2>
  <img class="profile" src="https://qingqu.engin.umich.edu/wp-content/uploads/sites/42/2021/08/AE0E7C9E-9D72-4FDB-9C6B-1D3E19DCCE72_1_105_c.jpeg" alt="Qing Qu">
  <p><strong>Yuxin Chen (yuxinc@wharton.upenn.edu)</strong> is a professor of statistics and of electrical and systems engineering at the University of Pennsylvania (UPenn). Before joining UPenn, he was an assistant professor of electrical and computer engineering at Princeton. He completed his Ph.D. in Electrical Engineering at Stanford University, and was also a postdoc scholar at Stanford Statistics. Dr. Chen‚Äôs expertise includes diffusion models, reinforcement learning theory, high-dimensional statistics, optimization, statistical learning theory, and information theory. His research accomplishments have been recognized by the Alfred P. Sloan Fellowship, the SIAM Imaging Science Best Paper Prize, the ICCM Best Paper Award (Gold Medal), the IEEE Transactions on Power Electronics Prize Paper Award (first place), and he was selected as a finalist for the Best Paper Prize for Young Researchers in Continuous Optimization. In addition, he has also received the Google Research Scholar Award and the Amazon Research Award. He has won six teaching awards and a Princeton Graduate Mentoring Award.</p>

  <section class="section">
  <h2>Dr. Chen‚Äôs Related Work and Experience:</h2>
  <p> Dr. Chen‚Äôs recent work [7‚Äì10, 20, 21] develops the state-of-the-art convergence theory for diffusion models. For instance, his work [7] provides the
first sharp convergence guarantees for the probability flow ODE sampler, while his work [21] is the first work that unveils the DDIM sampler‚Äôs ability to adapt to unknown low-dimensional structure of the target data distribution. Dr. Chen has presented a number of tutorials in conferences and workshops like SIGMETRICS [22], Joint Statistical Meetings [23], and ISIT [24].</p>

  <div class="figure">
    <img src="https://your_image_url_for_figure1a.png" alt="Reproducibility">
    <img src="https://your_image_url_for_figure1b.png" alt="Generalizability">
  </div>
  <p><strong>Figure 1:</strong> Co-emergence of reproducibility (3a) and generalizability (3b) of UNet architectures with three different parameter numbers (UNet-64, UNet-128, and UNet-256) in the denoising diffusion probabilistic model, which is trained on a varying number of images from the CIFAR-10 dataset. Figure courtesy of [10].</p>

  <section class="section">
    <h2>Papers</h2>
    <p><strong>Overview Paper:</strong></p>
  <ol>
    <li>
      <a href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=JfblW3MAAAAJ&sortby=pubdate&citation_for_view=JfblW3MAAAAJ:XD-gHx7UXLsC">Generalization of Diffusion Models: Principles, Theory, and Implications</a><br>
      H Zhang, P Wang, S Chen, Z Zhang, Q Qu<br>
      <em>SIAM News</em>
    </li>
  </ol>

  <p><strong>Phenomenon of generalization:</strong></p>
  <ol start="2">
    <li>
      Huijie Zhang*, Jinfan Zhou*, Yifu Lu, Minzhe Guo, Liyue Shen, Qing Qu.
      <a href="https://arxiv.org/abs/2310.05264">The Emergence of Reproducibility and Consistency in Diffusion Models</a>.
      International Conference on Machine Learning (ICML‚Äô24), 2024.<br>
      <a href="https://arxiv.org/abs/2310.05264">Preprint</a> ‚Äì <a href="https://arxiv.org/pdf/2310.05264.pdf">PDF</a> ‚Äì <a href="https://qingqu.engin.umich.edu/bibtex-zhang2023emergence/">BibTeX</a> ‚Äì <a href="https://qingqu.engin.umich.edu/wp-content/uploads/sites/42/2023/10/The_Emergence_of_Reproducibility_and_Consistency_in_Diffusion_Models_slides.pdf">Slides</a>
    </li>
    <li>
      Huijie Zhang, Zijian Huang, Siyi Chen, Jinfan Zhou, Zekai Zhang, Peng Wang, Qing Qu.
      <a href="https://arxiv.org/abs/2505.20123">Understanding Generalization in Diffusion Models via Probability Flow Distance</a>.
      Arxiv Preprint arXiv:2505.20123, 2025.
    </li>
  </ol>

  <p><strong>Theory on generalization:</strong></p>
  <ol start="4">
    <li>
      Peng Wang*, Huijie Zhang*, Zekai Zhang, Siyi Chen, Yi Ma, Qing Qu.
      <a href="https://arxiv.org/abs/2409.02426">Diffusion Models Learn Low-Dimensional Distributions via Subspace Clustering</a>.
      Arxiv Preprint arXiv:2409.02426, 2024.<br>
      <a href="https://arxiv.org/abs/2409.02426">Preprint</a> ‚Äì <a href="https://arxiv.org/pdf/2409.02426">PDF</a> ‚Äì <a href="https://www.huijiezh.com/diffusion-model-subspace-clustering/index.html">Project Website</a>
    </li>
    <li>
      Xiang Li, Yixiang Dai, Qing Qu.
      <a href="https://arxiv.org/abs/2410.24060">Understanding Generalizability of Diffusion Models Requires Rethinking the Hidden Gaussian Structure</a>.
      Neural Information Processing Systems (NeurIPS‚Äô24), 2024.<br>
      <a href="https://arxiv.org/abs/2410.24060">Preprint</a> ‚Äì <a href="https://arxiv.org/pdf/2410.24060">PDF</a> ‚Äì <a href="https://qingqu.engin.umich.edu/bibtex-li2024understanding/">BibTeX</a>
    </li>
  </ol>

  <p><strong>Applications/implications of generalization:</strong></p>
  <ol start="6">
    <li>
      Siyi Chen*, Huijie Zhang*, Minzhe Guo, Yifu Lu, Peng Wang, Qing Qu.
      <a href="https://arxiv.org/abs/2409.02374">Exploring Low-Dimensional Subspaces in Diffusion Models for Controllable Image Editing</a>.
      Neural Information Processing Systems (NeurIPS‚Äô24), 2024.<br>
      <a href="https://arxiv.org/abs/2409.02426">Preprint</a> ‚Äì <a href="https://arxiv.org/pdf/2409.02374">PDF</a> ‚Äì <a href="https://qingqu.engin.umich.edu/bibtex-chen2024exploring/">BibTeX</a> ‚Äì <a href="https://github.com/ChicyChen/LOCO-Edit">Code</a> ‚Äì <a href="https://chicychen.github.io/LOCO/index.html">Project Website</a>
    </li>
    <li>
      Wenda Li*, Huijie Zhang*, Qing Qu.
      <a href="https://arxiv.org/abs/2410.21088">Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models</a>.
      Arxiv Preprint arXiv:2410.21088, 2024.<br>
      <a href="https://arxiv.org/abs/2410.21088">Preprint</a> ‚Äì <a href="https://arxiv.org/pdf/2410.21088">PDF</a> ‚Äì <a href="https://qingqu.engin.umich.edu/bibtex-li2024shallow/">BibTeX</a> ‚Äì <a href="https://github.com/liwd190019/Shallow-Diffuse">Code</a> ‚Äì <a href="https://www.huijiezh.com/shallow-diffuse/">Project Website</a>
    </li>
    <li>
      Siyi Chen, Yimeng Zhang, Sijia Liu, Qing Qu.
      <a href="https://arxiv.org/abs/2504.21307">The Dual Power of Interpretable Token Embeddings: Jailbreaking Attacks and Defenses for Diffusion Model Unlearning</a>.
      Arxiv Preprint arXiv:2504.21307, 2025<br>
      <a href="https://arxiv.org/abs/2504.21307">Preprint</a> ‚Äì <a href="https://arxiv.org/pdf/2504.21307">PDF</a> ‚Äì <a href="#">BibTeX</a>
    </li>
    <li>
      Xiao Li*, Zekai Zhang*, Xiang Li, Siyi Chen, Zhihui Zhu, Peng Wang, Qing Qu.
      <a href="https://arxiv.org/abs/2502.05743">Understanding Representation Dynamics of Diffusion Models via Low-Dimensional Modeling</a>.
      Arxiv Preprint arXiv:2502.05743, 2025.
    </li>
    <li>
      Xiang Li, Rongrong Wang, Qing Qu.
      <a href="http://arxiv.org/abs/2505.19210">Towards Understanding the Mechanisms of Classifier-Free Guidance</a>.
      Arxiv Preprint arXiv:2505.19210, 2025.<br>
      <a href="http://arxiv.org/abs/2505.19210">Preprint</a> ‚Äì <a href="https://arxiv.org/pdf/2505.19210">PDF</a> ‚Äì <a href="#">BibTeX</a>
    </ul>
  </div>
</main>

<script>
function toggleSidebar() {
  const sidebar = document.getElementById('sidebar');
  sidebar.classList.toggle('collapsed');
  document.querySelector('.main').classList.toggle('collapsed');
}
</script>
</body>
</html>
